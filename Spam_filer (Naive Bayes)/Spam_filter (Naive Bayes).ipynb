{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Spam Filter using Naive Bayes Algorithm\n",
    "The goal of this project is to practice using the multinominal naive Bayes algorithm by building a spam filter for SMS messages.\n",
    "\n",
    "We are going to teach the computer how humans classify messages for spam or non-spam and then implement this knowledge to make the classification independently by estimating the probabilities of new messages are being spam or non spam.\n",
    "\n",
    "## Teaching\n",
    "Our first task is to \"teach\" the computer how to classify messages. To do this, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans (the \"ham\" means \"non spam\").\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "Let's explore the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages 5572\n",
      "Spam percentage is 13.406317300789663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sms_db = pd.read_csv('SMSSpamCollection',\n",
    "                     sep = '\\t',\n",
    "                     header = None,\n",
    "                     names = ['Label', 'SMS']                   \n",
    "                    )\n",
    "spam_percentage = sms_db[sms_db['Label'] == 'spam'].shape[0] / sms_db.shape[0]\n",
    "    \n",
    "print('Total messages {}'.format(sms_db.shape[0]))\n",
    "print('Spam percentage is {}'.format(spam_percentage * 100))\n",
    "\n",
    "sms_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing test and training sets\n",
    "We see there are 5572 messages with 13.4% of spam. All the classifications were made by humans.\n",
    "\n",
    "Before creating a spam filter we should think of a way of testing it. Also we should determine which result will be treated as a success. \n",
    "\n",
    "Let's randomly split our dataset into two categories:\n",
    "* A **training set** which we'll use to \"train\" the computer how to classify messages. It will take **80%** of our initial dataset\n",
    "* A **test set** of the remaining **20%** for the performance testing of our spam filter after completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam percentage in the training set is 13.458950201884253\n",
      "Spam percentage in the test set is 13.195691202872531\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset\n",
    "randomized_db = sms_db.sample(frac = 1,\n",
    "                              random_state = 1\n",
    "                             )\n",
    "num_rows = randomized_db.shape[0]\n",
    "\n",
    "# Getting 80% for the training set\n",
    "training_set = randomized_db.iloc[:int(round(num_rows*0.8,0))].copy()\n",
    "training_set.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Getting remaining 20% for the test set\n",
    "test_set = randomized_db.iloc[int(round(num_rows*0.8,0)):].copy()\n",
    "test_set.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Calculating spam percentages in both samples\n",
    "spam_percentage_training = (training_set[training_set['Label'] == 'spam'].shape[0]\n",
    "                            / training_set.shape[0])\n",
    "\n",
    "spam_percentage_test = (test_set[test_set['Label'] == 'spam'].shape[0]\n",
    "                              / test_set.shape[0])\n",
    "\n",
    "print('Spam percentage in the training set is {}'.format(spam_percentage_training * 100))\n",
    "print('Spam percentage in the test set is {}'.format(spam_percentage_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spam percentages of both new datasets are very similar to the initial one which means the splitting was made randomly enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning. No punctuation, lowercase\n",
    "The principle of the Naive Bayes algorithm is based on calculating the probabilities of every word mentioned in a message for being spam or non spam.\n",
    "\n",
    "To calculate this we need to consider each word regardless of case and punctuation.\n",
    "\n",
    "So we are going to clean our data by:\n",
    "1. Deleting all the punctuation\n",
    "2. Making all letters lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANTONT~1\\AppData\\Local\\Temp/ipykernel_15148/2481128332.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  training_set['SMS'] = training_set['SMS'].str.replace(r'\\W', ' ')\n",
      "C:\\Users\\ANTONT~1\\AppData\\Local\\Temp/ipykernel_15148/2481128332.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  training_set['SMS'] = training_set['SMS'].str.replace(r'\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "# Cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(r'\\W', ' ')\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(r'\\s+', ' ')\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes princess are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth there s a card on da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                        yep by the pretty sculpture\n",
       "1   ham        yes princess are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth there s a card on da..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vocabulary\n",
    "Now we need to create a vocabulary which will contain all the words from our training set. Firstly, we will split the 'SMS' column and transform every SMS into the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [yep, by, the, pretty, sculpture]\n",
       "1    [yes, princess, are, you, going, to, make, me,...\n",
       "2                      [welp, apparently, he, retired]\n",
       "3                                             [havent]\n",
       "4    [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "training_set['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll iterate over every SMS and take every word into a new list called \"vocabulary\". In other words we'll get a list of every word of every sms.\n",
    "\n",
    "The next step is to get rid from the duplicates. We can do this by transform our list into a set and back into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))    \n",
    "\n",
    "print(len(vocabulary)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done. Now we have a vocabulary which contains every unique word from all SMS in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dictionary\n",
    "The next step is to calculate the number of mentions of each word in each message. We are going to manage it by:\n",
    "1. Creating a dictionary with each unique word as a key\n",
    "2. Filling this dictionary with the lists of '0' values\n",
    "3. Iterating over the training dataset and counting the number of mentions of every word in every SMS\n",
    "4. Transforming the dictionary into the dataset which will have all the unique words as columns and all SMS messages as rows. The values will show how many time a specific word was mentioned in a specific message\n",
    "\n",
    "So from the data like this:\n",
    "\n",
    "![image](https://dq-content.s3.amazonaws.com/433/cpgp_dataset_1.png)\n",
    "\n",
    "we will get something like this:\n",
    "\n",
    "![image](https://dq-content.s3.amazonaws.com/433/cpgp_dataset_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {}\n",
    "for unique_word in vocabulary:\n",
    "    word_counts_per_sms[unique_word] = [0] * len(training_set['SMS'])\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\\\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print 3 rows with only relevant columns to check if reach what we wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disappeared</th>\n",
       "      <th>which</th>\n",
       "      <th>you</th>\n",
       "      <th>yeah</th>\n",
       "      <th>nice</th>\n",
       "      <th>worse</th>\n",
       "      <th>babe</th>\n",
       "      <th>and</th>\n",
       "      <th>hey</th>\n",
       "      <th>saw</th>\n",
       "      <th>...</th>\n",
       "      <th>is</th>\n",
       "      <th>second</th>\n",
       "      <th>rather</th>\n",
       "      <th>i</th>\n",
       "      <th>a</th>\n",
       "      <th>came</th>\n",
       "      <th>for</th>\n",
       "      <th>salmon</th>\n",
       "      <th>happened</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      disappeared  which  you  yeah  nice  worse  babe  and  hey  saw  ...  \\\n",
       "3612            0      0    1     0     1      0     0    0    0    0  ...   \n",
       "2553            0      1    0     1     0      1     0    0    0    0  ...   \n",
       "3879            1      0    2     0     0      0     1    1    1    1  ...   \n",
       "\n",
       "      is  second  rather  i  a  came  for  salmon  happened  online  \n",
       "3612   0       0       1  1  2     0    0       1         0       0  \n",
       "2553   1       0       0  1  0     0    1       0         0       0  \n",
       "3879   0       1       0  1  1     1    1       0         1       1  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = word_counts.sample(3)\n",
    "example.loc[:, example.loc[:, :].sum() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we wanted to get! But we haven't the SMS itself to make sure the calculation is right. Let's concatenate this data frame with the inintial training set. But firstly we need to be sure there are the same number of rows in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 7783)\n",
      "(4458, 2)\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.shape)\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, it's time for concatenating now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>you</th>\n",
       "      <th>retired</th>\n",
       "      <th>moan</th>\n",
       "      <th>me</th>\n",
       "      <th>to</th>\n",
       "      <th>he</th>\n",
       "      <th>yes</th>\n",
       "      <th>make</th>\n",
       "      <th>by</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yep</th>\n",
       "      <th>are</th>\n",
       "      <th>princess</th>\n",
       "      <th>welp</th>\n",
       "      <th>apparently</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>going</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  you  retired  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    0        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    1        0   \n",
       "2   ham                    [welp, apparently, he, retired]    0        1   \n",
       "\n",
       "   moan  me  to  he  yes  make  by  sculpture  yep  are  princess  welp  \\\n",
       "0     0   0   0   0    0     0   1          1    1    0         0     0   \n",
       "1     1   1   1   0    1     1   0          0    0    1         1     0   \n",
       "2     0   0   0   1    0     0   0          0    0    0         0     1   \n",
       "\n",
       "   apparently  the  pretty  going  \n",
       "0           0    1       1      0  \n",
       "1           0    0       0      1  \n",
       "2           1    0       0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.concat([training_set, word_counts], axis=1)\n",
    "\n",
    "# We'll take first 3 row for make sure evetything's fine\n",
    "head = word_counts.head(3)\n",
    "\n",
    "#Let's print only those columns which has at least 1 value\n",
    "head.loc[:, head.loc[:, :].sum() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating constants\n",
    "Now we have all the additional calculations and may start building a spam filter.\n",
    "The main advantage of the Naive Bayes algorithm is that the most computations are made before the classification itself. So the classification process is done almost instantly.\n",
    "\n",
    "At this stage we may determine parts of the algorithm which could be calculated only once and stay constant for every new SMS as we don't change the the training set.\n",
    "\n",
    "For this pupose we are going to split our training set into two parts:\n",
    "1. Spam\n",
    "2. Non spam\n",
    "\n",
    "and then calculate some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = word_counts[word_counts['Label'] == 'spam'].copy()\n",
    "ham_data = word_counts[word_counts['Label'] == 'ham'].copy()\n",
    "\n",
    "p_spam = spam_data.shape[0] / word_counts.shape[0]\n",
    "p_ham = 1 - p_spam\n",
    "\n",
    "# n_spam - a number of words in all spam messages\n",
    "n_spam = 0\n",
    "for sms in spam_data['SMS']:\n",
    "    n_spam += len(sms)\n",
    "\n",
    "# n_spam - a number of words in all ham messages\n",
    "n_ham = 0\n",
    "for sms in ham_data['SMS']:\n",
    "    n_ham += len(sms)\n",
    "\n",
    "# n_vocabulary - a number of unique words in all messages both spam and ham\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# alpha = 1, as we'll use Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dictionaries with probabilities of every word is being spam or ham\n",
    "We can also treat as a constant the probability of every word in our dictionary is being spam or non spam because it stays the same whatever new SMS message we'll be considering.\n",
    "\n",
    "Let's calculate the probability of every word is being spam or non spam. We'll create two dictionaries - one of probabilities of spam and another - of non spam. The keys will be unique words from our dictionary, the values will be '0'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_word_given_spam = dict.fromkeys(vocabulary, 0)\n",
    "p_word_given_ham = dict.fromkeys(vocabulary, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll update every value using the fomula from the Naive Bayes algorithm:\n",
    "\n",
    "P (word | spam) = (N (word | spam) + alpha) / (N (spam) + alpha * N (vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in p_word_given_spam:\n",
    "    n_word_spam = spam_data[word].sum()\n",
    "    p_word_given_spam[word] = ((n_word_spam + alpha)\n",
    "                               / (n_spam + alpha * n_vocabulary)\n",
    "                              )\n",
    "    \n",
    "    n_word_ham = ham_data[word].sum()\n",
    "    p_word_given_ham[word] = ((n_word_ham + alpha)\n",
    "                               / (n_ham + alpha * n_vocabulary)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a spam filter\n",
    "And finally we have everything ready to create a spam filter itself. It will be a function that takes in a message and classify it as spam or non spam using the knowledge from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \n",
    "    #some data cleaning with the new SMS \n",
    "    #(similar to we did creating the training set)\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    #Some math magic\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_word_given_spam:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "And that's it! Now as the function is ready we'll test it on our test set. We'll create a new column in the test set which will show the result of our algorithm's classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the final step is to measure the efficiency. We'll compare the algorithm's classification results with the humans' ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     98.743268\n",
       "False     1.256732\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['correct'] = test_set['Label'] == test_set['predicted']\n",
    "test_set.head()\n",
    "test_set['correct'].value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Wow! it's far above our expectation level of 80%.\n",
    "In this project we could assure how effective mathematics could be in practice.\n",
    "\n",
    "But one important thing we should bear in mind: the multinominal Naive Bayes algorithm don't sensitive to the combinations of words and determine the probability of each word of being spam or non spam independently from another words in a message.\n",
    "\n",
    "Nevertheless the efficiency of the algorithm shown on our test set is 98.7 % and the speed of calculation is pretty fast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
